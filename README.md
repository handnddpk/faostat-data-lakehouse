# Project Summary

## ğŸ¯ Complete Data Lakehouse - FAOSTAT Food Security Analysis

### Business Problem
**Question**: Which countries are at risk of food insecurity based on production and trade patterns?

**Solution**: Build an end-to-end data lakehouse analyzing global food production and trade data from FAOSTAT.

---

## ğŸ“ Project Structure

```
local-data-lakehouse/
â”œâ”€â”€ docker-compose.yml          # Full infrastructure
â”œâ”€â”€ Makefile                    # Quick commands
â”œâ”€â”€ setup.sh                    # Automated setup
â”œâ”€â”€ init_minio.py              # MinIO initialization
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ spark/
â”‚   â””â”€â”€ Dockerfile             # Spark with Iceberg
â”‚
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ faostat_pipeline.py  # Main orchestration DAG
â”‚
â”œâ”€â”€ jobs/
â”‚   â”œâ”€â”€ ingest_faostat.py        # Bronze: Data ingestion
â”‚   â”œâ”€â”€ transform_production.py  # Silver: Clean production
â”‚   â”œâ”€â”€ transform_trade.py       # Silver: Clean trade
â”‚   â””â”€â”€ analyze_food_security.py # Gold: Business metrics
â”‚
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ app.py                   # Streamlit dashboard
â”‚
â”œâ”€â”€ SECTIONS_CHEATSHEET.md       # Quick reference
â””â”€â”€ README.md
```

---

## ğŸ—ï¸ Architecture

### Tech Stack
- **Storage**: MinIO (S3-compatible object storage)
- **Compute**: Apache Spark 3.5
- **Table Format**: Apache Iceberg
- **Catalog**: PostgreSQL (JDBC)
- **Orchestration**: Apache Airflow
- **Dashboard**: Streamlit

### Data Flow (Medallion Architecture)
```
FAOSTAT API
    â†“
[Bronze Layer] Raw data in Iceberg tables
    â†“
[Silver Layer] Cleaned, structured data
    â†“
[Gold Layer] Business metrics & aggregations
    â†“
Streamlit Dashboard
```

---

## ğŸš€ Quick Start

```bash
# Start all services
make start

# Run the pipeline manually
make run-pipeline

# Access services
# MinIO:    http://localhost:9001 (admin/password)
# Spark:    http://localhost:8080
# Airflow:  http://localhost:8081 (admin/admin)
# Dashboard: http://localhost:8501
```

---

## ğŸ“Š Data Pipeline

### 1. Bronze Layer (Raw Data)
- **Input**: FAOSTAT bulk downloads
  - QCL: Crops and livestock products
  - TCL: Trade data (imports/exports)
- **Output**: 
  - `lakehouse.bronze.faostat_qcl_raw`
  - `lakehouse.bronze.faostat_tcl_raw`

### 2. Silver Layer (Cleaned Data)
- **Transformations**:
  - Filter relevant elements (Production, Exports, Imports)
  - Standardize column names
  - Clean data types
  - Remove nulls
- **Output**:
  - `lakehouse.silver.crop_production`
  - `lakehouse.silver.trade_data`

### 3. Gold Layer (Business Metrics)
- **Analytics**:
  - Yearly production by crop
  - Top crops globally
  - Trade balance (exports - imports)
  - Food security indicators
- **Output**:
  - `lakehouse.gold.yearly_crop_production`
  - `lakehouse.gold.top_crops`
  - `lakehouse.gold.trade_balance`
  - `lakehouse.gold.food_security_indicators`

### Key Metrics Calculated
- **Self-Sufficiency Ratio** = Production / (Production + Imports)
- **Production Growth Rate** = (Current Year - Previous Year) / Previous Year
- **Trade Balance** = Exports - Imports
- **Net Position** = Net Exporter | Net Importer | Balanced

---

## ğŸ‘¨â€ğŸ“ 5-Section Teaching Guide

### Section 1: Infrastructure Setup (2-3 hours)
**Focus**: Docker, MinIO, Spark, PostgreSQL
- Start services with docker-compose
- Initialize object storage
- Understand lakehouse architecture

### Section 2: Data Ingestion - Bronze (2-3 hours)
**Focus**: Ingest raw FAOSTAT data
- Download data from FAOSTAT API
- Load into Iceberg tables
- Understand table formats and catalogs

### Section 3: Data Transformation - Silver (3-4 hours)
**Focus**: Clean and structure data
- Transform production data
- Transform trade data
- Learn medallion architecture

### Section 4: Analytics & Orchestration - Gold (3-4 hours)
**Focus**: Business metrics and automation
- Calculate food security indicators
- Create Airflow DAG
- Automate pipeline

### Section 5: Visualization (2-3 hours)
**Focus**: Build dashboard
- Create Streamlit app
- Connect to Iceberg tables
- Generate insights

**Total Duration**: 12-15 hours (4 weeks, 3-4 hours per week)

---

## ğŸ“ Learning Outcomes

### Technical Skills
- Build data lakehouse with Iceberg
- Use Spark for large-scale processing
- Implement medallion architecture
- Orchestrate pipelines with Airflow
- Create interactive dashboards

### Concepts Mastered
- Data lake vs warehouse vs lakehouse
- Object storage patterns
- Schema evolution
- Workflow orchestration
- Business intelligence

### Real-World Application
- Map business requirements to data pipeline
- Design scalable data architecture
- Calculate business metrics
- Present insights to stakeholders

---

## ğŸ“ˆ Business Insights Generated

1. **Production Trends**: Which crops are growing/declining?
2. **Trade Dependencies**: Which countries rely on imports?
3. **Food Security Risk**: Countries with low self-sufficiency
4. **Regional Analysis**: Production patterns by geography
5. **Crop Priorities**: Most important crops globally

### Sample Findings
- Countries with <50% self-sufficiency are high risk
- Declining production growth indicates capacity issues
- Net importers are vulnerable to supply disruptions

---

## ğŸ”§ Manual Pipeline Execution

```bash
# 1. Ingest production data
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  /opt/spark/jobs/ingest_faostat.py QCL

# 2. Transform production data
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  /opt/spark/jobs/transform_production.py

# 3. Ingest trade data
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  /opt/spark/jobs/ingest_faostat.py TCL

# 4. Transform trade data
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  /opt/spark/jobs/transform_trade.py

# 5. Analyze food security
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  /opt/spark/jobs/analyze_food_security.py
```

---

## ğŸ¨ Dashboard Features

### Tab 1: Production
- Top 10 crops by production
- Production trends over time
- Interactive crop selection

### Tab 2: Trade
- Top exporters and importers
- Trade balance visualization
- Country comparison

### Tab 3: Food Security
- Self-sufficiency ratios
- Countries at risk
- Trend analysis

### Tab 4: Insights
- Risk distribution pie chart
- Countries with declining production
- Summary statistics

---

## ğŸ› ï¸ Troubleshooting

```bash
# View logs
make logs

# Stop all services
make stop

# Clean everything and restart
make clean
make start

# Check service status
docker ps

# Restart specific service
docker-compose restart spark-master
```

---

## ğŸ“š Additional Resources

### Datasets
- FAOSTAT QCL: Crops and livestock production
- FAOSTAT TCL: Trade (crops and livestock)
- FAOSTAT FBS: Food balance sheets (optional extension)

### Documentation
- Apache Iceberg: https://iceberg.apache.org/
- Apache Spark: https://spark.apache.org/
- Apache Airflow: https://airflow.apache.org/
- Streamlit: https://streamlit.io/

---

## ğŸš€ Extensions for Advanced Students

1. **Data Quality**: Add Great Expectations validation
2. **Incremental Updates**: Use Iceberg merge operations
3. **Additional Data**: Combine with population/GDP data
4. **Machine Learning**: Predict future production
5. **dbt Integration**: Use dbt for transformations
6. **Time Travel**: Implement Iceberg time travel queries
7. **Authentication**: Add user login to dashboard
8. **Alerting**: Email notifications for at-risk countries
9. **API**: Build REST API for data access
10. **CI/CD**: Add automated testing and deployment

---

## âœ… Success Criteria

### For Students
- [ ] All services running successfully
- [ ] Complete pipeline executed without errors
- [ ] Dashboard displays all visualizations
- [ ] Can explain each component's role
- [ ] Can answer: "Which countries are at risk and why?"

---

## ğŸ“ Key Takeaways

1. **Lakehouse = Best of Both Worlds**
   - Data lake flexibility + warehouse performance

2. **Medallion Architecture = Data Quality**
   - Bronze â†’ Silver â†’ Gold ensures clean, reliable data

3. **Iceberg = Modern Table Format**
   - ACID transactions, schema evolution, time travel

4. **Orchestration = Automation**
   - Airflow manages dependencies and scheduling

5. **Business Value = The Goal**
   - Technology serves business insights, not vice versa

---

## ğŸ¯ Project Goal Achieved

**Question**: Which countries are at risk of food insecurity?

**Answer**: Countries with:
- Self-sufficiency ratio <50%
- Negative production growth
- High import dependency
- Low cereal production

**Evidence**: Interactive dashboard showing risk indicators with historical trends and real-time data updates.

---

Built with â¤ï¸ for hands-on learning
